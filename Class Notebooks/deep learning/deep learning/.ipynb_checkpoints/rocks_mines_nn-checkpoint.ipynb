{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\"\n",
    "df = pd.read_csv(url,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[0:60]].values\n",
    "y = df[df.columns[60]].values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Converting the y values into numbers</h2>\n",
    "<li>In our regression example, we used 0 for rocks and 1 for mines\n",
    "<li>sklearn has a LabelEncoder that will replace text with numbered labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>That's not optimal because:\n",
    "<ol>\n",
    "<li>0 < 1 but rocks are not less than mines or mines less than rocks\n",
    "<li>The average of 0 and 1 is meaningless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>One-hot encoding</h2>\n",
    "<li>comes from digital electronics\n",
    "<li>only binary values are allowed\n",
    "<li>all values are 0 except for one 1 (the \"one hot\" part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Example</h2>\n",
    "Consider the following data fragment:\n",
    "<table>\n",
    "<tr><td>Name</td><td>Income</td><td>City</td></tr>\n",
    "<tr><td>John</td><td>120000</td><td>New York</td></tr>\n",
    "<tr><td>Jill</td><td>20000</td><td>Chicago</td></tr>\n",
    "<tr><td>Jae</td><td>75000</td><td>New York</td></tr>\n",
    "<tr><td>Jane</td><td>179000</td><td>Los Angeles</td></tr>\n",
    "<tr><td>Jake</td><td>10000</td><td>Los Angeles</td></tr>\n",
    "</table>\n",
    "<li>We want to encode City. One option:\n",
    "<table>\n",
    "<tr><td>Name</td><td>Income</td><td>City</td></tr>\n",
    "<tr><td>John</td><td>120000</td><td>1</td></tr>\n",
    "<tr><td>Jill</td><td>20000</td><td>2</td></tr>\n",
    "<tr><td>Jae</td><td>75000</td><td>1</td></tr>\n",
    "<tr><td>Jane</td><td>179000</td><td>3</td></tr>\n",
    "<tr><td>Jake</td><td>10000</td><td>3</td></tr>\n",
    "</table>\n",
    "<li>But New York is not less than Chicago (quite the contrary!)\n",
    "<li>Nor is Chicago the average of New York and LA (that would be weird!)\n",
    "<li>Better to replace City with the following \"one hot encoding\"\n",
    "<table>\n",
    "<tr><td>Name</td><td>Income</td><td>New York</td><td>Chicago</td><td>Los Angeles</td></tr>\n",
    "<tr><td>John</td><td>120000</td><td>1</td><td>0</td><td>0</td></tr>\n",
    "<tr><td>Jill</td><td>20000</td><td>0</td><td>1</td><td>0</td></tr>\n",
    "<tr><td>Jae</td><td>75000</td><td>1</td><td>0</td><td>0</td></tr>\n",
    "<tr><td>Jane</td><td>179000</td><td>0</td><td>0</td><td>1</td></tr>\n",
    "<tr><td>Jake</td><td>10000</td><td>0</td><td>0</td><td>1</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>One hot encoder</h2>\n",
    "<li>general function to do one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array = np.array(['New York','Chicago','New York','Los Angeles','Los Angeles'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>convert data into numerical labels</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder.fit(array)\n",
    "coded_array = encoder.transform(array)\n",
    "coded_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>create a one hot coded array</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(coded_array)\n",
    "n_labels = len(np.unique(coded_array))\n",
    "n_labels\n",
    "one_hot = np.zeros((n,n_labels))\n",
    "#np.arange(n),coded_array\n",
    "one_hot[np.arange(n), coded_array] = 1\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(array):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    encoder.fit(array)\n",
    "    coded_array = encoder.transform(array)\n",
    "    n = len(coded_array)\n",
    "    n_labels = len(np.unique(coded_array))\n",
    "    one_hot = np.zeros((n,n_labels))\n",
    "    one_hot[np.arange(n), coded_array] = 1\n",
    "    return one_hot\n",
    "one_hot_encoder(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>One hot encode the y (rocks/mines) column</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=one_hot_encoder(y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create a training and a testing data set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size = 0.20, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Building the neural net</h1>\n",
    "<li>We need to decide:\n",
    "<ol>\n",
    "<li>Number of hidden layers\n",
    "<li>Number of nodes in each hidden layer\n",
    "<li>Number of nodes in the input layer\n",
    "<li>Number of nodes in the output layer\n",
    "<li>Number of training passes (epochs)\n",
    "<li>Activation function to use\n",
    "<li>The \"learning rate\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Learning rate</h3>\n",
    "A hyper parameter that controls how much weights should be adjusted after each epoch\n",
    "<li>Too low, the model will take a long time to converge (expensive GPU cost)\n",
    "<li>Too high, the model may never converge\n",
    "<li>Bit of guesswork goes into this (e.g., start low, slowly increase the rate, see how the loss changes (loss = prediction error), and adjust the rate accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>hidden layers</h3>\n",
    "<li>We'll start with one hidden layer\n",
    "<li>With 60 nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layers = (60,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Input layer</h3>\n",
    "<li>60 input nodes, corresponding to each sonar frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Output layer</h3>\n",
    "<li>2 classes, one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>learning rate</h3>\n",
    "<li>start low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Passes/epochs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>sklearn has a Multi-layer Perceptron Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(60,), max_iter = 500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>If you must know!</h3>\n",
    "<li><b>solver</b>: sgd (sigmoid), lbfgs (limited memory Broyden–Fletcher–Goldfarb–Shanno algorithm), adam (stochastic gradient based optimizer)\n",
    "<li><b>activation</b>: logistic (sigmoid), tanh (hyperbolic tan function), relu (linear unit function). relu returns max(0,x) and works better on two class dependent variables (we don't want both returned\n",
    "<li><b>alpha</b>: L2 regularization term. Regularization is used to prevent overfitting by not using the exact loss (difference between predicted and actual) when adjusting the weights (in a neural network model). L2 adds the sum of the square of the weights modified by a lambda parameter to each delta\n",
    "<li><b>batch size</b>: Number of cases to use in one epoch. \n",
    "<li><b>momentum</b>: A number between 0 and 1 that accelerates a gradient descent (e.g., sigmoid) algorithm if it is moving in the right (consistent) direction\n",
    "<li><b>shuffle</b>: shuffle the samples in each iteration (the order in which they are presented will change\n",
    "<li><b>tol</b>: if the improvement is less than this, the algorithm stops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actuals = ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp=tn=fp=fn=0\n",
    "for i in range(len(actuals)):\n",
    "    a_class=p_class=0\n",
    "    if int(actuals[i][0] == 0):\n",
    "        a_class = 1 \n",
    "    if int(predictions[i][0] == 0):\n",
    "        p_class = 1\n",
    "    if a_class == 1 and p_class == 1:\n",
    "        tp +=1\n",
    "    elif a_class == 1 and p_class == 0:\n",
    "        fn +=1\n",
    "    elif a_class == 0 and p_class == 0:\n",
    "        tn +=1\n",
    "    elif a_class == 0 and p_class == 1:\n",
    "        fp +=1\n",
    "print(tp,tn,fp,fn)\n",
    "print(\"Accuracy: %1.2f\"%((tp+tn)*100/(tp+tn+fp+fn)))\n",
    "#(tp+tn)/(tp+tn+fp+fn)*100 )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
